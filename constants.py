
# Gap and Coverage Validation
GAP_WARNING_THRESHOLD_CHARS = 2000
SUBSTANTIVE_GAP_THRESHOLD_CHARS = 500
ANCHOR_SEARCH_BUFFER_BEFORE = 5000
ANCHOR_SEARCH_EXTENDED_WINDOW = 50000
TABLE_TRUNCATION_THRESHOLD_RATIO = 0.80
EXTRACTION_COMPLETE_THRESHOLD_PCT = 95.0
DUPLICATE_WARNING_THRESHOLD_RATIO = 1.5
SECTION_INTRO_MIN_LENGTH_CHARS = 100

# Token Estimation
ESTIMATED_TOKENS_PER_SECTION_METADATA = 100
TOKENS_PER_SECTION_ESTIMATE = 2000
ESTIMATED_TOKENS_PER_FIELD = 80
ESTIMATED_TOKENS_PER_TABLE = 500
ESTIMATED_TOKENS_PER_SECTION = 150

# Model Configuration (Defaults - actual values from config)
MODEL_CONTEXT_TOKENS = 400_000
MAX_OUTPUT_TOKENS = 128_000
SYSTEM_PROMPT_TOKENS = 2_500
SAFETY_MARGIN_TOKENS = 5_000
AVAILABLE_INPUT_TOKENS = MODEL_CONTEXT_TOKENS - SYSTEM_PROMPT_TOKENS - SAFETY_MARGIN_TOKENS  # 392,500

# Batching
SAFE_OUTPUT_TOKENS = 64_000
MAX_SECTIONS_PER_BATCH = 25
SUPER_CHUNK_THRESHOLD_TOKENS = 200_000

# Chunking
CHUNK_THRESHOLD_TOKENS = int(AVAILABLE_INPUT_TOKENS * 0.90)   # ~353k
CHUNK_MAX_SIZE_TOKENS = int(AVAILABLE_INPUT_TOKENS * 0.95)    # ~373k
CHUNK_MIN_SIZE_TOKENS = int(AVAILABLE_INPUT_TOKENS * 0.50)    # ~196k
CHUNK_MAX_SIZE = int(CHUNK_MAX_SIZE_TOKENS * 2.5)
CHUNK_MIN_SIZE = int(CHUNK_MIN_SIZE_TOKENS * 2.5)
OVERLAP_SIZE = 4_000

# Retry
RATE_LIMIT_RETRY_BASE_DELAY = 1.0
